{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from src.data import Data\n",
    "from src.utils.color import to_float_rgb\n",
    "\n",
    "# Set your file path for imports\n",
    "file_path = os.path.dirname(os.path.abspath(''))  # for .ipynb notebook\n",
    "sys.path.append(file_path)\n",
    "\n",
    "def read_custom_tile(filepath, xyz=True, rgb=True, intensity=True, semantic=True, remap=True):\n",
    "    \"\"\"\n",
    "    Read a custom dataset saved as .h5 and return the data in a structured format.\n",
    "\n",
    "    :param filepath: str\n",
    "        Absolute path to the .h5 file.\n",
    "    :param xyz: bool\n",
    "        Whether XYZ coordinates should be saved in the output Data.pos.\n",
    "    :param rgb: bool\n",
    "        Whether RGB colors should be saved in the output Data.rgb.\n",
    "    :param intensity: bool\n",
    "        Whether intensity should be saved in the output Data.intensity.\n",
    "    :param semantic: bool\n",
    "        Whether semantic labels should be saved in the output Data.y.\n",
    "    :param remap: bool\n",
    "        Whether to remap labels to a trainable format (e.g., reassigning label indices).\n",
    "    \"\"\"\n",
    "    # Create an empty Data object\n",
    "    data = Data()\n",
    "\n",
    "    # Read the .h5 file\n",
    "    with h5py.File(filepath, 'r') as f:\n",
    "        pointcloud = f['pointcloud'][:]\n",
    "        # pointcloud = np.array(f['pointcloud'], dtype=np.float32)\n",
    "    \n",
    "    # Populate data with point coordinates (XYZ)\n",
    "    if xyz:\n",
    "        data.pos = torch.tensor(pointcloud[:, :3], dtype=torch.float32)\n",
    "\n",
    "    # Populate data with point RGB colors\n",
    "    if rgb:\n",
    "        data.rgb = to_float_rgb(torch.tensor(pointcloud[:, 4:7], dtype=torch.float32))\n",
    "\n",
    "    # Populate data with point LiDAR intensity\n",
    "    if intensity:\n",
    "        data.intensity = torch.tensor(pointcloud[:, 3], dtype=torch.float32)  # 'i' for intensity\n",
    "\n",
    "    # Populate data with point semantic segmentation labels\n",
    "    if semantic:\n",
    "        labels = pointcloud[:, 7]  # 'l' stands for label\n",
    "        data.y = torch.LongTensor(labels)\n",
    "        if remap:\n",
    "            data.y = torch.from_numpy(ID2TRAINID)[data.y]\n",
    "\n",
    "    return data\n",
    "\n",
    "# def read_custom_tile(filepath, xyz=True, rgb=True, intensity=True, semantic=True, remap=True):\n",
    "#     \"\"\"\n",
    "#     Read a .pts/txt file and return the data in a structured format.\n",
    "\n",
    "#     :param filepath: str\n",
    "#         Absolute path to the .pts file.\n",
    "#     :param xyz: bool\n",
    "#         Whether XYZ coordinates should be saved in the output Data.pos.\n",
    "#     :param rgb: bool\n",
    "#         Whether RGB colors should be saved in the output Data.rgb.\n",
    "#     :param intensity: bool\n",
    "#         Whether intensity should be saved in the output Data.intensity.\n",
    "#     :param semantic: bool\n",
    "#         Whether semantic labels should be saved in the output Data.y.\n",
    "#     :param remap: bool\n",
    "#         Whether to remap labels to a trainable format (e.g., reassigning label indices).\n",
    "#     :return: Data\n",
    "#         A structured data object with the desired attributes.\n",
    "#     \"\"\"\n",
    "#     # Create an empty Data object\n",
    "#     data = Data()\n",
    "\n",
    "#     # Read the .pts file\n",
    "#     pointcloud = np.loadtxt(filepath)\n",
    "\n",
    "#     # Populate data with point coordinates (XYZ)\n",
    "#     if xyz:\n",
    "#         data.pos = torch.tensor(pointcloud[:, :3], dtype=torch.float32)\n",
    "\n",
    "#     # Populate data with point RGB colors\n",
    "#     if rgb and pointcloud.shape[1] >= 6:\n",
    "#         data.rgb = to_float_rgb(torch.tensor(pointcloud[:, 3:6], dtype=torch.float32))\n",
    "\n",
    "#     # Populate data with point LiDAR intensity\n",
    "#     if intensity and pointcloud.shape[1] >= 7:\n",
    "#         data.intensity = torch.tensor(pointcloud[:, 6], dtype=torch.float32)\n",
    "\n",
    "#     # Populate data with point semantic segmentation labels\n",
    "#     if semantic and pointcloud.shape[1] >= 8:\n",
    "#         labels = pointcloud[:, 7]  # 'l' stands for label\n",
    "#         data.y = torch.LongTensor(labels)\n",
    "#         if remap:\n",
    "#             data.y = torch.from_numpy(ID2TRAINID)[data.y]\n",
    "\n",
    "#     return data\n",
    "\n",
    "# Number of classes in your dataset (excluding void/unlabeled/ignored)\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# Mapping from original classes to new training class IDs (if remapping is necessary)\n",
    "ID2TRAINID = np.asarray([\n",
    "    # NUM_CLASSES,  # 0 -> Ignored\n",
    "    0,            # 1 -> Class 0 (e.g., 'Window')\n",
    "    1,          # 2 -> Class 1 (e.g., 'Wall')\n",
    "    2             # 3 -> Class 2 (e.g., 'Door')\n",
    "])\n",
    "\n",
    "# Class names (including void/unlabeled/ignored last)\n",
    "# CLASS_NAMES = [\n",
    "#     'Window',\n",
    "#     'Wall',\n",
    "#     'Door',\n",
    "#     # 'Ignored'\n",
    "# ]\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    'Window + doors',\n",
    "    'Wall',\n",
    "    'Others',\n",
    "    # 'Ignored'\n",
    "]\n",
    "\n",
    "# Class color palette (including void/unlabeled/ignored last)\n",
    "CLASS_COLORS = np.asarray([\n",
    "    [255, 255, 0],    # Yellow for 'Window'\n",
    "    [0, 255, 0],      # Green for 'Wall'\n",
    "    [0, 0, 255]      # Blue for 'Others'\n",
    "    # [0, 0, 0]         # Black for 'Ignored'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd\n",
    "filepath = '/mnt/e/pointnet2_pytorch_semantic/data/s3dis/buildings_3_labels_original/FRP2_SE.h5'#B4020_SE.h5' #FRP2_NW.h5'\n",
    "# filepath = 'data/building/raw/test/KCDC111-112_S_processed.h5'# FRP2_NW.h5'KCDC111-112_W_processed.h5'\n",
    "# filepath = '/mnt/e/debbie/FRP2_october_trimmed.txt'\n",
    "# filepath = \"/mnt/e/superpoint_transformer/NRC_DATA/all/NRCAN_cropped.txt\"\n",
    "# filepath =\"NRC_DATA/all/NRCAN_cropped.txt\" #KCDC_dummy.txt\" \n",
    "data = read_custom_tile(filepath)\n",
    "# print(data.shape)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data positions: {data.pos.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.num_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.show(class_colors = CLASS_COLORS,class_names = CLASS_NAMES, max_points=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.show(center=[4.25, 2.82, 1.5], radius=30, keys=['intensity'], class_names=CLASS_NAMES, class_colors=CLASS_COLORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.transforms import SampleXYTiling, GridSampling3D\n",
    "# from src.data import Batch\n",
    "\n",
    "# # Tile the cloud into `xy_tiling` XY-oriented chunks of equal horizontal \n",
    "# # span\n",
    "# xy_tiling = (1, 1)\n",
    "\n",
    "# # Voxelize the point cloud only for the sake of faster computation and \n",
    "# # visualization here\n",
    "# # data_5m = GridSampling3D(0.009)(data)\n",
    "# data_5m = data\n",
    "\n",
    "# # Compute each chunk \n",
    "# chunks = []\n",
    "# for x in range(xy_tiling[0]):\n",
    "#     for y in range(xy_tiling[1]):        \n",
    "#         # Extract the chunk at (x, y) in the tiling grid\n",
    "#         chunk = SampleXYTiling(x=x, y=y, tiling=xy_tiling)(data_5m)\n",
    "\n",
    "#         # Add a 'tile' attribute to the points for visualization\n",
    "#         chunk.tile = torch.full((chunk.num_points,), x * xy_tiling[1] + y)\n",
    "        \n",
    "#         # Store the chunk for later aggregation\n",
    "#         chunks.append(chunk)\n",
    "\n",
    "# # Aggregate all chunk `Data` objects into one big `Data` object\n",
    "# data_tiled = Batch.from_data_list(chunks)\n",
    "\n",
    "# # Show the resulting `Data' with the 'tile' attribute\n",
    "# data_tiled.show(keys='tile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.transforms import SampleRecursiveMainXYAxisTiling, GridSampling3D\n",
    "# from src.data import Batch\n",
    "\n",
    "# # Recursively tile the cloud into `2**pc_tiling` chunks with respect to \n",
    "# # principal components of the XY coordiantes\n",
    "# pc_tiling = 2\n",
    "\n",
    "# # Voxelize the point cloud only for the sake of faster computation and \n",
    "# # visualization here\n",
    "# # data_5m = GridSampling3D(0.009)(data)\n",
    "# data_5m = data\n",
    "# # Compute each chunk \n",
    "# chunks = []\n",
    "# for x in range(2**pc_tiling):\n",
    "#     # Extract the chunk at x in the recursive tiling\n",
    "#     chunk = SampleRecursiveMainXYAxisTiling(x=x, steps=pc_tiling)(data_5m)\n",
    "\n",
    "#     # Add a 'tile' attribute to the points for visualization\n",
    "#     chunk.tile = torch.full((chunk.num_points,), x)\n",
    "    \n",
    "#     # Store the chunk for later aggregation\n",
    "#     chunks.append(chunk)\n",
    "\n",
    "# # Aggregate all chunk `Data` objects into one big `Data` object\n",
    "# data_tiled = Batch.from_data_list(chunks)\n",
    "\n",
    "# # Show the resulting `Data' with the 'tile' attribute\n",
    "# data_tiled.show(keys='tile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.transforms import SampleXYTiling\n",
    "\n",
    "# # Extract the chunk at (x, y) in the tiling grid\n",
    "# data = SampleXYTiling(x=0, y=0, tiling=4)(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import init_config\n",
    "\n",
    "# cfg = init_config(overrides=[f\"experiment=semantic/dales\"])\n",
    "cfg = init_config(overrides=[f\"experiment=semantic/building\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = init_config(overrides=[f\"experiment=semantic/s3dis\"])\n",
    "# cfg.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transforms import instantiate_datamodule_transforms\n",
    "\n",
    "transforms_dict = instantiate_datamodule_transforms(cfg.datamodule)\n",
    "transforms_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Shape of coords: {coords.shape}\")\n",
    "print(f\"Data positions: {data.pos.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pre-transforms\n",
    "nag = transforms_dict['pre_transform'](data)\n",
    "\n",
    "# Simulate the behavior of the dataset's I/O behavior with only\n",
    "# `point_load_keys` and `segment_load_keys` loaded from disk\n",
    "from src.transforms import NAGRemoveKeys\n",
    "nag = NAGRemoveKeys(level=0, keys=[k for k in nag[0].keys if k not in cfg.datamodule.point_load_keys])(nag)\n",
    "nag = NAGRemoveKeys(level='1+', keys=[k for k in nag[1].keys if k not in cfg.datamodule.segment_load_keys])(nag)\n",
    "\n",
    "# Move to device\n",
    "nag = nag.cuda()\n",
    "\n",
    "# Apply on-device transforms\n",
    "nag = transforms_dict['on_device_test_transform'](nag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nag.show(class_names=CLASS_NAMES, class_colors=CLASS_COLORS, center=[485, 505, 0], radius=0.02, keys=nag[0].keys, centroids=True, h_edge=True)\n",
    "# nag.show(class_names=CLASS_NAMES, class_colors=CLASS_COLORS,radius =20, keys=nag[0].keys, centroids=True, h_edge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra \n",
    "from src.utils import init_config\n",
    "\n",
    "# Path to the checkpoint file downloaded from https://zenodo.org/records/8042712\n",
    "# ckpt_path = \"/path/to/your/superpoint_transformer.ckpt\"\n",
    "# ckpt_path = \"/mnt/e/superpoint_transformer/logs/train/runs/2024-10-28_10-05-50/checkpoints/epoch_959.ckpt\"\n",
    "# ckpt_path = \"/mnt/e/superpoint_transformer/logs/train/runs/2024-10-23_16-02-51/checkpoints/epoch_1659.ckpt\"\n",
    "# ckpt_path = \"/mnt/e/superpoint_transformer/logs/train/runs/2024-10-26_13-04-21/checkpoints/epoch_1789.ckpt\"\n",
    "# ckpt_path = \"/mnt/e/superpoint_transformer/logs/train/runs/2024-10-28_11-28-29/checkpoints/epoch_1889.ckpt\"\n",
    "# ckpt_path = \"/mnt/e/superpoint_transformer/logs/train/runs/2024-10-30_10-37-41/checkpoints/epoch_849.ckpt\"  # 2 labels 1000 epochs\n",
    "ckpt_path = \"/mnt/e/superpoint_transformer/logs/train/runs/2024-11-13_11-05-27/checkpoints/epoch_879.ckpt\" # 2 labels 1000 epochs new parameters \n",
    "\n",
    "# cfg = init_config(overrides=[f\"experiment=semantic/s3dis\"])\n",
    "cfg = init_config(overrides=[f\"experiment=semantic/building\"])\n",
    "\n",
    "# Instantiate the model and load pretrained weights\n",
    "model = hydra.utils.instantiate(cfg.model)\n",
    "model = model._load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model in inference mode on the same device as the input\n",
    "model = model.eval().to(nag.device)\n",
    "\n",
    "# Inference, returns a task-specific ouput object carrying predictions\n",
    "with torch.no_grad():\n",
    "    output = model(nag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.semantic_pred.shape, nag.num_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the level-0 (voxel-wise) semantic segmentation predictions \n",
    "# based on the predictions on level-1 superpoints and save those for \n",
    "# visualization in the level-0 Data under the 'semantic_pred' attribute\n",
    "\n",
    "nag[0].semantic_pred = output.voxel_semantic_pred(super_index=nag[0].super_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.datasets.dales import CLASS_NAMES as DALES_CLASS_NAMES\n",
    "# from src.datasets.dales import CLASS_COLORS as DALES_CLASS_COLORS\n",
    "\n",
    "# from src.datasets.s3dis import CLASS_NAMES \n",
    "# from src.datasets.s3dis import CLASS_COLORS\n",
    "# from src.datasets.building import CLASS_NAMES \n",
    "# from src.datasets.building import CLASS_COLORS\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    'Window + Door',\n",
    "    'Wall',\n",
    "    'Others'\n",
    "]\n",
    "\n",
    "CLASS_COLORS = np.asarray([\n",
    "    [255, 255, 0],  # Class 0: Yellow for 'Window + Door'\n",
    "    [0, 255, 0],    # Class 1: Green for 'Wall'\n",
    "    [0, 0, 255]     # Class 2: Blue for 'Others'\n",
    "])\n",
    "\n",
    "# nag.show(class_names=CLASS_NAMES, class_colors=CLASS_COLORS)#, radius=10)\n",
    "nag.show(class_names=CLASS_NAMES,class_colors=CLASS_COLORS,max_points=500000,centroids=False,v_edge=True, h_edge=True)#,title=\"KCDC_visualization\",path=\"KCDC_visualization.html\")#,gap=[4, 4, 0])\n",
    "# nag.show(class_names=CLASS_NAMES,class_colors=CLASS_COLORS,stuff_classes=dataset.stuff_classes,num_classes=dataset.num_classes,max_points=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of sizes of successive partition levels\n",
    "nag.level_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nag[2].semantic_segmentation_oracle(NUM_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oracle semantic segmentation metrics on P_1\n",
    "print(nag[1].semantic_segmentation_oracle(NUM_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oracle semantic segmentation metrics on P_0\n",
    "print(nag[0].semantic_segmentation_oracle(NUM_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_dict['pre_transform']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
